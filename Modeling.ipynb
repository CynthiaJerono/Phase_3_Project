{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>local_government_area</th>\n",
       "      <th>population</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_type</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>status_group</th>\n",
       "      <th>construction_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>109</td>\n",
       "      <td>False</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "      <td>1990s (1990-1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>280</td>\n",
       "      <td>True</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "      <td>2000s (2000-2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>Simanjiro</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>functional</td>\n",
       "      <td>2000s (2000-2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>dry</td>\n",
       "      <td>borehole</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>non functional</td>\n",
       "      <td>1980s (1980-1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>Karagwe</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh date_recorded        funder  gps_height  \\\n",
       "0      6000.0    2011-03-14         Roman        1390   \n",
       "1         0.0    2013-03-06       Grumeti        1399   \n",
       "2        25.0    2013-02-25  Lottery Club         686   \n",
       "3         0.0    2013-01-28        Unicef         263   \n",
       "4         0.0    2011-07-13   Action In A           0   \n",
       "\n",
       "                     basin   region local_government_area  population  permit  \\\n",
       "0               Lake Nyasa   Iringa                Ludewa         109   False   \n",
       "1            Lake Victoria     Mara             Serengeti         280    True   \n",
       "2                  Pangani  Manyara             Simanjiro         250    True   \n",
       "3  Ruvuma / Southern Coast   Mtwara              Nanyumbu          58    True   \n",
       "4            Lake Victoria   Kagera               Karagwe           0    True   \n",
       "\n",
       "   construction_year extraction_type_class management_group payment_type  \\\n",
       "0               1999               gravity       user-group     annually   \n",
       "1               2010               gravity       user-group    never pay   \n",
       "2               2009               gravity       user-group   per bucket   \n",
       "3               1986           submersible       user-group    never pay   \n",
       "4                  0               gravity            other    never pay   \n",
       "\n",
       "  water_quality      quantity           source_type  \\\n",
       "0          soft        enough                spring   \n",
       "1          soft  insufficient  rainwater harvesting   \n",
       "2          soft        enough                   dam   \n",
       "3          soft           dry              borehole   \n",
       "4          soft      seasonal  rainwater harvesting   \n",
       "\n",
       "               waterpoint_type    status_group construction_decade  \n",
       "0           communal standpipe      functional   1990s (1990-1999)  \n",
       "1           communal standpipe      functional   2000s (2000-2009)  \n",
       "2  communal standpipe multiple      functional   2000s (2000-2009)  \n",
       "3  communal standpipe multiple  non functional   1980s (1980-1989)  \n",
       "4           communal standpipe      functional             Unknown  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd.read_csv('./Data/clean_data.csv', index_col=0)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['region', 'extraction_type_class', 'management_group', 'funder',\n",
    "                    'quantity', 'water_quality' , 'waterpoint_type', 'source_type', 'status_group' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['amount_tsh','gps_height', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(['date_recorded', 'construction_year', 'basin', 'local_government_area', \n",
    "                     'payment_type', 'permit', 'construction_decade'], axis=1, inplace=True)\n",
    "#to be dropped before one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode the categorical columns in the DataFrame\n",
    "for col in categorical_cols:\n",
    "    df_model[col] = encoder.fit_transform(df_model[col])\n",
    "\n",
    "# covert categorical columns to integer\n",
    "for col in categorical_cols:\n",
    "    df_model[col] = df_model[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from category_encoders import OneHotEncoder\n",
    "#ohe = OneHotEncoder(cols = categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_model = ohe.fit_transform(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_type</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1319</td>\n",
       "      <td>1390</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>457</td>\n",
       "      <td>1399</td>\n",
       "      <td>9</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>803</td>\n",
       "      <td>686</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1681</td>\n",
       "      <td>263</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  funder  gps_height  region  population  extraction_type_class  \\\n",
       "0      6000.0    1319        1390       3         109                      0   \n",
       "1         0.0     457        1399       9         280                      0   \n",
       "2        25.0     803         686       8         250                      0   \n",
       "3         0.0    1681         263      12          58                      5   \n",
       "4         0.0      18           0       4           0                      0   \n",
       "\n",
       "   management_group  water_quality  quantity  source_type  waterpoint_type  \\\n",
       "0                 4              6         1            6                1   \n",
       "1                 4              6         2            3                1   \n",
       "2                 4              6         1            1                2   \n",
       "3                 4              6         0            0                2   \n",
       "4                 1              6         3            3                1   \n",
       "\n",
       "   status_group  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X = df_model.drop('status_group', axis=1)\n",
    "y = df_model['status_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56344 entries, 0 to 59399\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   amount_tsh             56344 non-null  float64\n",
      " 1   funder                 56344 non-null  int32  \n",
      " 2   gps_height             56344 non-null  int64  \n",
      " 3   region                 56344 non-null  int32  \n",
      " 4   population             56344 non-null  int64  \n",
      " 5   extraction_type_class  56344 non-null  int32  \n",
      " 6   management_group       56344 non-null  int32  \n",
      " 7   water_quality          56344 non-null  int32  \n",
      " 8   quantity               56344 non-null  int32  \n",
      " 9   source_type            56344 non-null  int32  \n",
      " 10  waterpoint_type        56344 non-null  int32  \n",
      "dtypes: float64(1), int32(8), int64(2)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data is now ready to be modeled. To begin, we will fit a dummy cllassifier model as my baseline model and analyze its performance indicators. Following that, I will fit several more classification models and evaluate their performance measures.\n",
    "\n",
    "I will choose the two best-performing models from the four models based on accuracy. The remaining two models will subsequently be tuned with ensemble methods.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dummy Classifier - Baseline model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DummyClassifier makes predictions that ignore the input features. This classifier serves as a simple baseline to compare against other more complex classifiers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of accuracy, the dummy classifier achieves an accuracy of 0.53, meaning that it correctly predicts the class for around 53% of the instances.\n",
    "\n",
    "- Overall, these results indicate that the dummy classifier performs poorly in predicting class 1, as it never correctly identifies any instances of that class. It performs better in predicting class 0, achieving a reasonable precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70      7534\n",
      "           1       0.00      0.00      0.00      6552\n",
      "\n",
      "    accuracy                           0.53     14086\n",
      "   macro avg       0.27      0.50      0.35     14086\n",
      "weighted avg       0.29      0.53      0.37     14086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build a pipeline with a StandardScaler and a DummyClassifier\n",
    "dummy_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                ('dummy', DummyClassifier(random_state=42))])\n",
    "# fit the pipeline to the training set\n",
    "dummy_pipe.fit(X_train, y_train)\n",
    "# make predictions on the test set\n",
    "y_pred_dummy = dummy_pipe.predict(X_test)\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom color palette\n",
    "color_palette = sns.color_palette(\"Blues\")\n",
    "\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dummy), annot=True, fmt='g', cmap=color_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a LogisticRegression classifier\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('logreg', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training set\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logreg = logreg_pipeline.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. The intuition behind Decision Trees is that you use the dataset features to create yes/no questions and continually split the dataset until you isolate all data points belonging to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with a decision tree classifier as the estimator:\n",
    "dt = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('tree', DecisionTreeClassifier(random_state=42))])\n",
    "# fit the pipeline to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "# make predictions on the test set\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix without a color palette\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='g')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy score represents the proportion of correctly predicted instances out of the total number of instances. In this case, the decision tree model achieved an accuracy of around 0.75, indicating that it predicted 75% of instances correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A Random Forest Classifier is a popular machine learning algorithm used for classification tasks. It belongs to the family of ensemble methods, which combine multiple individual models to make predictions. The Random Forest algorithm constructs a multitude of decision trees during training and outputs the class that is the mode of the classes predicted by the individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with a StandardScaler and a RandomForestClassifier.\n",
    "rf = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('rf', RandomForestClassifier(random_state=42))])\n",
    "# fit the pipeline to the training data\n",
    "rf.fit(X_train, y_train);\n",
    "# make predictions on the test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='g', cmap=color_palette);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The overall accuracy of the model is 0.78, indicating that it correctly predicts approximately 78% of the instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Support Vector Machine (SVM) classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A Support Vector Machine (SVM) classifier is a powerful supervised machine learning algorithm used for both classification and regression tasks. It is particularly effective in handling high-dimensional feature spaces and datasets with clear separation between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the trained pipeline\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='g', cmap=color_palette);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The overall accuracy of the model is 0.73, indicating that it correctly predicts approximately 73% of the instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. K-Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> K-Nearest Neighbors (KNN) is a simple yet effective machine learning algorithm used for both classification and regression tasks. It is a non-parametric algorithm that makes predictions based on the similarity of data points in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('knn_clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of the model is 0.76, indicating that it correctly classifies 76% of the instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. K-Nearest Neighbors with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid_knn = {\n",
    "    'knn_clf__n_neighbors': [3, 5, 7],\n",
    "    'knn_clf__weights': ['uniform', 'distance'],\n",
    "    'knn_clf__p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gridsearch_knn = GridSearchCV(estimator=knn_clf, param_grid=param_grid_knn, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "gridsearch_knn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_knn = gridsearch_knn.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params_knn)\n",
    "\n",
    "# Make predictions on the test data using the trained pipeline\n",
    "y_pred_gridsearchknn = gridsearch_knn.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gridsearchknn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: The best parameters found during the grid search are:\n",
    "\n",
    "- Number of neighbors (knn_clf__n_neighbors): 7\n",
    "- Distance metric power parameter (knn_clf__p): 1\n",
    "- Weighting scheme (knn_clf__weights): 'distance'\n",
    "\n",
    "\n",
    "- Accuracy: The accuracy of the model is 0.77, indicating that it correctly classifies 77% of the instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Decision Tree with GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('tree', DecisionTreeClassifier(random_state=42))])\n",
    "# create a grid of parameters to test\n",
    "\n",
    "param_grid = [{'tree__max_depth': [16, 18, 20],\n",
    "              'tree__min_samples_split': [4, 6, 8],\n",
    "              'tree__min_samples_leaf': [2, 3, 4],\n",
    "              'tree__criterion': ['gini', 'entropy']}]\n",
    "\n",
    "# create grid with estimators\n",
    "gridsearch_dt = GridSearchCV(dt, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# fit the grid with the data    \n",
    "gridsearch_dt.fit(X_train, y_train);\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_dt = gridsearch_dt.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params_dt)\n",
    "# Make predictions on the test data using the trained pipeline\n",
    "y_pred_gridsearchdt = gridsearch_dt.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gridsearchdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gridsearchdt), annot=True, fmt='g', cmap=color_palette);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Random Forest with GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_depth': [7, 8],\n",
    "    'rf__max_features': [7, 8],\n",
    "    'rf__min_samples_leaf': [1, 2],\n",
    "    'rf__min_samples_split': [2, 3],\n",
    "    'rf__criterion': ['gini', 'entropy'],\n",
    "    'rf__bootstrap': [True, False],\n",
    "    'rf__random_state': [42]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gridsearch_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "gridsearch_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_rf = gridsearch_rf.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params_rf)\n",
    "\n",
    "# Make predictions on the test data using the trained pipeline\n",
    "y_pred_gridsearchrf = gridsearch_rf.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gridsearchrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gridsearchrf), annot=True, fmt='g', cmap=color_palette);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Parameters: The best parameters found during the grid search are:\n",
    "\n",
    "    - Bootstrap (rf__bootstrap): False\n",
    "    - Splitting criterion (rf__criterion): 'gini'\n",
    "    - Maximum depth of trees (rf__max_depth): 8\n",
    "    - Maximum number of features considered for splitting (rf__max_features): 7\n",
    "    - Minimum number of samples required to be at a leaf node (rf__min_samples_leaf): 2\n",
    "    - Minimum number of samples required to split an internal node (rf__min_samples_split): 2\n",
    "    - Number of trees in the random forest (rf__n_estimators): 300\n",
    "    - Random state for reproducibility (rf__random_state): 42\n",
    "\n",
    " - The accuracy of the model is 0.74, indicating that it correctly classifies 74% of the instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model was the Random Forest Classifier with an accuracy of 78% and KNN with grid search with an accuracy of 77%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lake Rukwa basin area, where there are considerably more non-functional wells than functional ones, may be worth considering for our stakeholders when they decide to build more wells in Tanzania. There are more non-functional wells than functioning ones in the Dodoma region; this situation has to be investigated. Over the course of time, wells with operating permission typically become more viable and useful than those without. Due to possible public misuse, unpaid wells frequently become inoperable; perhaps creating a reasonable payment plan will help stop this. Because wells without permissions also have a higher likelihood of becoming inoperable, our stakeholder must verify that they have permits to ensure that they are acceptable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
